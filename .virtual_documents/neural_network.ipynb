import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


import torch
from torch import nn


train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")


train.head()


# let's separate numeric columns and categorical columns 
num_cols = train.select_dtypes(include=np.number).columns.tolist()
num_cols.remove('id')
cat_cols = train.select_dtypes(include = ['object', 'string']).columns.tolist()


num_features = ['study_hours', 'class_attendance', 'sleep_hours']
cat_features = cat_cols   # your categorical columns

X = train[num_features + cat_features]
y = train['exam_score']


X = pd.get_dummies(X, drop_first=True)
X = X.astype(int)
X.head()


X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42
)


# Scale the inputs
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# convert to tensor 

# X Training data
X_train =  torch.tensor(X_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)

# y training data 
y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1,1)
y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1,1)


# device agnostic code
device ="cuda" if torch.cuda.is_available() else "cpu"


X.shape


# create a neural network 
class ExamScore(nn.Module):
    def __init__(self, in_features):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_features, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )

    def forward(self, x):
        return self.net(x)



model_0 = ExamScore(in_features=X.shape[1])
model_0.to(device)


# define loss function and optimizer 
loss_fn = nn.L1Loss()

# set optimizer
optimizer = torch.optim.Adam(model_0.parameters(), lr=0.02)


epochs = 2000
patience = 20   # stop if no improvement for 20 epochs

best_test_loss = float("inf")
epochs_no_improve = 0

for epoch in range(epochs):

    # ----- TRAIN -----
    model_0.train()
    y_pred = model_0(X_train)
    train_loss = loss_fn(y_pred, y_train)

    optimizer.zero_grad()
    train_loss.backward()
    optimizer.step()

    # ----- TEST -----
    model_0.eval()
    with torch.inference_mode():
        test_pred = model_0(X_test)
        test_loss = loss_fn(test_pred, y_test)

    # ----- EARLY STOPPING CHECK (EVERY EPOCH) -----
    if test_loss.item() < best_test_loss:
        best_test_loss = test_loss.item()
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    if epochs_no_improve >= patience:
        print(f"Early stopping at epoch {epoch}")
        break

    # ----- LOGGING -----
    if epoch % 100 == 0:
        print(
            f"Epoch {epoch} | "
            f"Train Loss: {train_loss.item():.4f} | "
            f"Test Loss: {test_loss.item():.4f}"
        )
        print("-" * 50)






epochs = 2000
patience = 20   # stop if no improvement for 20 epochs

best_test_loss = float("inf")
epochs_no_improve = 0

for epoch in range(epochs):

    # ----- TRAIN -----
    model_0.train()
    y_pred = model_0(X_train)
    train_loss = loss_fn(y_pred, y_train)

    optimizer.zero_grad()
    train_loss.backward()
    optimizer.step()

    # ----- TEST -----
    model_0.eval()
    with torch.inference_mode():
        test_pred = model_0(X_test)
        test_loss = loss_fn(test_pred, y_test)

    # ----- EARLY STOPPING CHECK (EVERY EPOCH) -----
    if test_loss.item() < best_test_loss:
        best_test_loss = test_loss.item()
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    if epochs_no_improve >= patience:
        print(f"Early stopping at epoch {epoch}")
        break

    # ----- LOGGING -----
    if epoch % 100 == 0:
        print(
            f"Epoch {epoch} | "
            f"Train Loss: {train_loss.item():.4f} | "
            f"Test Loss: {test_loss.item():.4f}"
        )
        print("-" * 50)



test = test[num_features + cat_features]
X = pd.get_dummies(test, drop_first=True)
X = X.astype(int)
X.head()


X_test_kaggle = scaler.transform(X)

X_test_kaggle = torch.from_numpy(X_test_kaggle).float()
X_test_kaggle = X_test_kaggle.to(device)

model_0.eval()

with torch.no_grad():
    predictions = model_0(X_test_kaggle)

predictions = predictions.cpu().numpy().flatten()


submission = pd.read_csv("sample_submission.csv")
submission["exam_score"] = predictions   # use target column name
submission.to_csv("submission.csv", index=False)



